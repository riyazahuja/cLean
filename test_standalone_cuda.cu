/*
 * Standalone CUDA Test Program
 *
 * Tests the CUDA kernels generated by cLean to verify they compile and execute correctly.
 * Compile with: nvcc -o test_standalone_cuda test_standalone_cuda.cu
 * Run with: ./test_standalone_cuda
 */

#include <cuda_runtime.h>
#include <stdio.h>
#include <stdlib.h>
#include <math.h>

// Error checking macro
#define CUDA_CHECK(call) \
do { \
    cudaError_t err = call; \
    if (err != cudaSuccess) { \
        fprintf(stderr, "CUDA error at %s:%d: %s\n", __FILE__, __LINE__, \
                cudaGetErrorString(err)); \
        exit(EXIT_FAILURE); \
    } \
} while(0)

/*
 * Kernel 1: SAXPY (Generated by cLean)
 * r[i] = alpha * x[i] + y[i]
 */
__global__ void saxpyKernel(int N, float alpha, float* x, float* y, float* r) {
  int i = ((blockIdx.x * blockDim.x) + threadIdx.x);
  if ((i < N)) {
    float xi = x[i];
    float yi = y[i];
    r[i] = ((alpha * xi) + yi);
  }
}

/*
 * Kernel 2: Vector Addition (Generated by cLean)
 * c[i] = a[i] + b[i]
 */
__global__ void vecAddKernel(int N, float* a, float* b, float* c) {
  int i = ((blockIdx.x * blockDim.x) + threadIdx.x);
  if ((i < N)) {
    float ai = a[i];
    float bi = b[i];
    c[i] = (ai + bi);
  }
}

/*
 * Kernel 3: Scalar Multiplication
 * output[i] = scale * input[i]
 */
__global__ void scaleMulKernel(int N, float scale, float* input, float* output) {
  int i = ((blockIdx.x * blockDim.x) + threadIdx.x);
  if ((i < N)) {
    float val = input[i];
    output[i] = (scale * val);
  }
}

/* Test helper function */
bool floatArraysEqual(float* a, float* b, int n, float epsilon = 1e-5) {
    for (int i = 0; i < n; i++) {
        if (fabsf(a[i] - b[i]) > epsilon) {
            printf("Mismatch at index %d: %.6f != %.6f (diff: %.6e)\n",
                   i, a[i], b[i], fabsf(a[i] - b[i]));
            return false;
        }
    }
    return true;
}

/* Test 1: SAXPY */
bool testSaxpy() {
    printf("\n=== Test 1: SAXPY ===\n");

    const int N = 16;
    const float alpha = 2.5f;
    const size_t size = N * sizeof(float);

    // Host arrays
    float h_x[N], h_y[N], h_r[N], h_expected[N];

    // Initialize data
    for (int i = 0; i < N; i++) {
        h_x[i] = (float)(i + 1);
        h_y[i] = 1.0f;
        h_expected[i] = alpha * h_x[i] + h_y[i];
    }

    // Device arrays
    float *d_x, *d_y, *d_r;
    CUDA_CHECK(cudaMalloc(&d_x, size));
    CUDA_CHECK(cudaMalloc(&d_y, size));
    CUDA_CHECK(cudaMalloc(&d_r, size));

    // Copy to device
    CUDA_CHECK(cudaMemcpy(d_x, h_x, size, cudaMemcpyHostToDevice));
    CUDA_CHECK(cudaMemcpy(d_y, h_y, size, cudaMemcpyHostToDevice));

    // Launch kernel
    int threadsPerBlock = 256;
    int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;
    saxpyKernel<<<blocksPerGrid, threadsPerBlock>>>(N, alpha, d_x, d_y, d_r);
    CUDA_CHECK(cudaGetLastError());
    CUDA_CHECK(cudaDeviceSynchronize());

    // Copy result back
    CUDA_CHECK(cudaMemcpy(h_r, d_r, size, cudaMemcpyDeviceToHost));

    // Verify
    printf("Input: alpha=%.1f, x=[%.1f, %.1f, ...], y=[%.1f, %.1f, ...]\n",
           alpha, h_x[0], h_x[1], h_y[0], h_y[1]);
    printf("Output: r=[%.1f, %.1f, %.1f, %.1f, ...]\n",
           h_r[0], h_r[1], h_r[2], h_r[3]);
    printf("Expected: [%.1f, %.1f, %.1f, %.1f, ...]\n",
           h_expected[0], h_expected[1], h_expected[2], h_expected[3]);

    bool passed = floatArraysEqual(h_r, h_expected, N);

    // Cleanup
    CUDA_CHECK(cudaFree(d_x));
    CUDA_CHECK(cudaFree(d_y));
    CUDA_CHECK(cudaFree(d_r));

    if (passed) {
        printf("✓ SAXPY test PASSED\n");
    } else {
        printf("✗ SAXPY test FAILED\n");
    }

    return passed;
}

/* Test 2: Vector Addition */
bool testVecAdd() {
    printf("\n=== Test 2: Vector Addition ===\n");

    const int N = 8;
    const size_t size = N * sizeof(float);

    // Host arrays
    float h_a[N], h_b[N], h_c[N], h_expected[N];

    // Initialize data
    for (int i = 0; i < N; i++) {
        h_a[i] = (float)(i + 1);
        h_b[i] = (float)(N - i);
        h_expected[i] = h_a[i] + h_b[i];
    }

    // Device arrays
    float *d_a, *d_b, *d_c;
    CUDA_CHECK(cudaMalloc(&d_a, size));
    CUDA_CHECK(cudaMalloc(&d_b, size));
    CUDA_CHECK(cudaMalloc(&d_c, size));

    // Copy to device
    CUDA_CHECK(cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice));
    CUDA_CHECK(cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice));

    // Launch kernel
    int threadsPerBlock = 256;
    int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;
    vecAddKernel<<<blocksPerGrid, threadsPerBlock>>>(N, d_a, d_b, d_c);
    CUDA_CHECK(cudaGetLastError());
    CUDA_CHECK(cudaDeviceSynchronize());

    // Copy result back
    CUDA_CHECK(cudaMemcpy(h_c, d_c, size, cudaMemcpyDeviceToHost));

    // Verify
    printf("Output: c=[%.1f, %.1f, %.1f, %.1f, %.1f, %.1f, %.1f, %.1f]\n",
           h_c[0], h_c[1], h_c[2], h_c[3], h_c[4], h_c[5], h_c[6], h_c[7]);
    printf("Expected: [%.1f, %.1f, %.1f, %.1f, %.1f, %.1f, %.1f, %.1f]\n",
           h_expected[0], h_expected[1], h_expected[2], h_expected[3],
           h_expected[4], h_expected[5], h_expected[6], h_expected[7]);

    bool passed = floatArraysEqual(h_c, h_expected, N);

    // Cleanup
    CUDA_CHECK(cudaFree(d_a));
    CUDA_CHECK(cudaFree(d_b));
    CUDA_CHECK(cudaFree(d_c));

    if (passed) {
        printf("✓ Vector Addition test PASSED\n");
    } else {
        printf("✗ Vector Addition test FAILED\n");
    }

    return passed;
}

/* Test 3: Scalar Multiplication */
bool testScaleMul() {
    printf("\n=== Test 3: Scalar Multiplication ===\n");

    const int N = 50;
    const float scale = 2.0f;
    const size_t size = N * sizeof(float);

    // Host arrays
    float* h_input = (float*)malloc(size);
    float* h_output = (float*)malloc(size);
    float* h_expected = (float*)malloc(size);

    // Initialize data
    for (int i = 0; i < N; i++) {
        h_input[i] = (float)i;
        h_expected[i] = scale * h_input[i];
    }

    // Device arrays
    float *d_input, *d_output;
    CUDA_CHECK(cudaMalloc(&d_input, size));
    CUDA_CHECK(cudaMalloc(&d_output, size));

    // Copy to device
    CUDA_CHECK(cudaMemcpy(d_input, h_input, size, cudaMemcpyHostToDevice));

    // Launch kernel
    int threadsPerBlock = 256;
    int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;
    scaleMulKernel<<<blocksPerGrid, threadsPerBlock>>>(N, scale, d_input, d_output);
    CUDA_CHECK(cudaGetLastError());
    CUDA_CHECK(cudaDeviceSynchronize());

    // Copy result back
    CUDA_CHECK(cudaMemcpy(h_output, d_output, size, cudaMemcpyDeviceToHost));

    // Verify (show first few)
    printf("scale=%.1f\n", scale);
    printf("Output (first 10): [%.1f, %.1f, %.1f, %.1f, %.1f, %.1f, %.1f, %.1f, %.1f, %.1f]\n",
           h_output[0], h_output[1], h_output[2], h_output[3], h_output[4],
           h_output[5], h_output[6], h_output[7], h_output[8], h_output[9]);

    bool passed = floatArraysEqual(h_output, h_expected, N);

    // Cleanup
    CUDA_CHECK(cudaFree(d_input));
    CUDA_CHECK(cudaFree(d_output));
    free(h_input);
    free(h_output);
    free(h_expected);

    if (passed) {
        printf("✓ Scalar Multiplication test PASSED\n");
    } else {
        printf("✗ Scalar Multiplication test FAILED\n");
    }

    return passed;
}

int main() {
    printf("========================================\n");
    printf("  Standalone CUDA Kernel Tests\n");
    printf("  (Testing cLean-generated CUDA code)\n");
    printf("========================================\n");

    // Check CUDA availability
    int deviceCount = 0;
    cudaError_t err = cudaGetDeviceCount(&deviceCount);

    if (err != cudaSuccess || deviceCount == 0) {
        fprintf(stderr, "No CUDA devices found!\n");
        return EXIT_FAILURE;
    }

    // Print device info
    cudaDeviceProp prop;
    CUDA_CHECK(cudaGetDeviceProperties(&prop, 0));
    printf("\nUsing GPU: %s\n", prop.name);
    printf("Compute Capability: %d.%d\n", prop.major, prop.minor);

    // Run tests
    bool allPassed = true;
    allPassed &= testSaxpy();
    allPassed &= testVecAdd();
    allPassed &= testScaleMul();

    // Summary
    printf("\n========================================\n");
    if (allPassed) {
        printf("  ✓ ALL TESTS PASSED!\n");
        printf("========================================\n");
        return EXIT_SUCCESS;
    } else {
        printf("  ✗ SOME TESTS FAILED\n");
        printf("========================================\n");
        return EXIT_FAILURE;
    }
}
